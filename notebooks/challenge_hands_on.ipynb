{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/DonErnesto/amld2021-unsupervised/blob/master/notebooks/challenge_hands_on.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Workshop challenge"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "0ek6rUiPXRC-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Package installing and data import"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "FsyJ1d24Z9Je"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load the required files...\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab, need to get data and install libraries..')\n",
    "    data_path = './'\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/amld2021-unsupervised/master/notebooks/outlierutils.py\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/amld2021-unsupervised/master/data/x_kdd_prepared.csv\n",
    "    !pip install --upgrade pyod\n",
    "else:\n",
    "    print('Not running on CoLab, data and libraries are already present')\n",
    "    data_path = '../data'\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import getpass\n",
    "\n",
    "# pandas, seaborn etc.\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn outlier models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# other sklearn functions\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.covariance import MinCovDet, EmpiricalCovariance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import scale as preproc_scale\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# pyod\n",
    "import pyod\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "# from pyod.models.pca import PCA as pyod_PCA\n",
    "from pyod.models.iforest import IForest"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from outlierutils import plot_top_N, plot_outlier_scores, LabelSubmitter, API_URL"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_kdd = pd.read_csv(os.path.join(data_path, 'x_kdd_prepared.csv'))\n",
    "x_kdd = x_kdd.drop_duplicates()\n",
    "if x_kdd.index.max() > len(x_kdd):\n",
    "    x_kdd = x_kdd.reset_index()\n",
    "print(f'Data set size: {x_kdd.shape}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Challenge Description\n",
    "\n",
    "You just imported a data set, `x_kdd`, with 48K rows. The dataset was collected by by MIT Lincoln Labs in 1999, by operating a LAN-network as usual, and additionally carrying out various attacks. This specific dataset (which is a subset of the original dataset) has \"normal\" traffic as inlier class, and several attacks (buffer_overflow, ftp_write, imap, ...) as outlier class. Although this data does not represent payment fraud, it is relevant because of the mixed data type. \n",
    "\n",
    "\n",
    "There are no labels available, there is therefore also no split in train and test. \n",
    "The target is to predict as many true positives as possible (each positive gets you a positive score), and as few false positives as possible (each false positive subtracts a small score). So only submit points that may likely be positives!!\n",
    "\n",
    "\n",
    "Be selective, just submitting all points, or random points, will not get you a good score :)\n",
    "\n",
    "- Each true positive found yields **500** points\n",
    "- Each false positive costs **25** points\n",
    "\n",
    "**Hints**\n",
    "\n",
    "- The fraction of positives is less than 1%. Random guessing to gather labels is therefore unlikely to pay off. \n",
    "- When sufficiently many positive labels are available, this information may be used to further tune unsupervised algorithms, or to train a supervised classifier\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First clean up the data: convert categorical columns to one-hot encoded, and MinMax-scale all features. Do not remove any rows!\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# clean-up code here\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Outlier detection: your code!\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_top_N_indices(scores, N=100):\n",
    "    \"\"\" Helper function. Returns the indices of the points with the top N highest outlier scores\n",
    "    \"\"\"\n",
    "    return np.argsort(scores)[::-1][:N]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_top_N_indices(np.array([5, 4, 3, 2, 1, 0]), N=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## API submission\n",
    "\n",
    "Submit your predictions to the API with a LabelSubmitter object. \n",
    "This object has a `.post_predictions()` method to submit predictions, and a `.get_labels()` method to retrieve the labels (positives and negatives) of all previous submissions. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "username='test'\n",
    "password = getpass.getpass()\n",
    "if not ('ls' in locals() and ls.jwt_token): #only if no labelsubmitter with .jwt_token is available\n",
    "    ls = LabelSubmitter(username=username,\n",
    "                       password=password,\n",
    "                       url=API_URL)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the parameter `endpoint='kdd'` option for this challenge. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ls.post_predictions(idx=[0, 1], endpoint='kdd')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = ls.get_labels(endpoint='kdd')\n",
    "labels"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
