{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DonErnesto/amld2021-unsupervised/blob/master/notebooks/solutions_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Demonstration of several algorithms on the Pen Digits dataset\n",
    "\n",
    "Exercises using the Pen Digits Dataset: https://www.dbs.ifi.lmu.de/research/outlier-evaluation/DAMI/literature/PenDigits/PenDigits_v01.html\n",
    "\n",
    "The data is already present in .pkl format (load the data below).\n",
    "This data set was created by recording the writing pattern of digits on a digital writing pad. The digit \"4\" is downsampled to only 20 instances (instead of ~1000 for the other points), making it an outlier. \n",
    "\n",
    "Note that (unlike MNIST), the features do not simply correspond to pixels, but are subsampled coordinates, 8 pairs. \n",
    "\n",
    "This dataset is small and simple: it has only numeric features and no NaN's. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package installing and data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab, need to get data and install libraries..')\n",
    "    data_path = './'\n",
    "    # Now only load the required files...\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/amld2021-unsupervised/master/notebooks/outlierutils.py\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/amld2021-unsupervised/master/data/x_pendigits.csv\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/amld2021-unsupervised/master/data/y_pendigits.csv\n",
    "    !pip install --upgrade pyod\n",
    "else:\n",
    "    print('Not running on CoLab, data and libraries are already present')\n",
    "    data_path = '../data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlierutils import plot_top_N, plot_outlier_scores # For easy plotting and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_outliers = False # replaces the original outliers with \"synthetic\" ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x_pen = pd.read_csv(os.path.join(data_path, 'x_pendigits.csv'))\n",
    "y_pen = pd.read_csv(os.path.join(data_path, 'y_pendigits.csv'))['outlier']\n",
    "\n",
    "# Scale and put again into a DataFrame\n",
    "sc = StandardScaler()\n",
    "x_pen = pd.DataFrame(data=sc.fit_transform(x_pen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if replace_outliers:\n",
    "    new_values = pd.concat((x_pen.sample(20, random_state=1).iloc[:, :8].reset_index(drop=True),\n",
    "           x_pen.sample(20, random_state=2).iloc[:, 8:].reset_index(drop=True)),\n",
    "         axis=1).set_index(y_pen[y_pen==1].index)\n",
    "    x_pen.loc[y_pen==1, :] = new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of points: {len(y_pen)}')\n",
    "print(f'Number of positives: {y_pen.sum()} ({y_pen.mean():.3%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "axs = axs.ravel()\n",
    "for i in range(5):\n",
    "    axs[i].imshow(np.reshape(x_pen.loc[i].values, (4, 4)), cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "fig.suptitle('Non-outlier')\n",
    "    \n",
    "outlier = y_pen[y_pen == 1]  \n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "axs = axs.ravel()\n",
    "for i in range(5):\n",
    "    axs[i].imshow(np.reshape(x_pen.loc[outlier.index[i]].values, (4, 4)), cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "fig.suptitle('Outlier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "N_downsample = 3000\n",
    "assert x_pen.index.equals(y_pen.index), 'Error, indexes differ. Reset them to continue'\n",
    "x_downsampled = pd.concat((x_pen[y_pen==0].sample(N_downsample - int(y_pen.sum()), random_state=1),\n",
    "                           x_pen[y_pen==1]), \n",
    "                          axis=0).sample(frac=1, random_state=1)\n",
    "y_downsampled = y_pen[x_downsampled.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_N_TSNE = 3500 #Avoid overly long computation times with TSNE. Values < 5000 recommended \n",
    "neg = y_downsampled == 0\n",
    "pos = y_downsampled == 1\n",
    "\n",
    "assert len(x_downsampled) <= MAX_N_TSNE, 'Using a dataset with more than {} points is not recommended'.format(\n",
    "                                            MAX_N_TSNE)\n",
    "X_2D = TSNE(n_components=2, \n",
    "            perplexity=50, \n",
    "            n_iter=400,\n",
    "           random_state=5).fit_transform(x_downsampled) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.scatter(X_2D[pos, 0], X_2D[pos, 1], c=[[0.8, 0.4, 0.4],], marker='x', s=120, label='Positive')\n",
    "ax.scatter(X_2D[neg, 0], X_2D[neg, 1], c=[[0.2, 0.3, 0.9],], marker='s', s=10, label='Negative')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.0\n",
    "\n",
    "Some observations (with **original** outliers):\n",
    "- Depending on the perplexity, we see roughly 10 clusters, not all well-defined. This is in line with the expectation to see 9 + 1 (the 9 digits plus \"4\", the undersampled outlier class)\n",
    "- The outlier class forms a single cluster, rather than being scattered across\n",
    "- This corresponds to our understanding of the data: the outlier class is really an under-represented class\n",
    "\n",
    "\n",
    "With the **synthetic outliers** (replacing the original ones), outliers are scattered across rather than close together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the Mahalonobis distance in two ways:\n",
    "- Directly: Calculating the Covariance matrix (with the full data, or with the robust MinCovDet), then the Mahalonobis distance\n",
    "- Indirectly: Do a whitened PCA decompose with full-rank, calculate the Euclidean distance\n",
    "\n",
    "We will take the first option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import MinCovDet, EmpiricalCovariance\n",
    "\n",
    "cov_ = EmpiricalCovariance().fit(x_pen)\n",
    "#cov_ = MinCovDet().fit(x_pen) # Robust estimation\n",
    "mahalonobis_scores = cov_.mahalanobis(x_pen)\n",
    "mahalonobis_scores = np.clip(mahalonobis_scores, 0, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_outlier_scores(y_pen.values, mahalonobis_scores, bw=2, title='Pen digits, Mahalonobis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_top_N(y_pen.values, mahalonobis_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mahalonobis results\n",
    "\n",
    "**original** outliers: \n",
    "\n",
    "AUC-ROC-score: 0.81, AUC-PR: 0.006, P@100 1%\n",
    "\n",
    "**synthetic** outliers: \n",
    "\n",
    "ROC-score: 0.82, P@100 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=9, covariance_type='full', random_state=1) # try also spherical\n",
    "gmm.fit(x_pen, )\n",
    "gmm_scores = - gmm.score_samples(x_pen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_scores = np.clip(gmm_scores, -15, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_outlier_scores(y_pen.values, gmm_scores, bw=2, title='Pen digits, Mahalonobis (GMM)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_top_N(y_pen.values, gmm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ds = gmm.predict(x_downsampled)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "n_components = gmm.n_components\n",
    "for i, class_ in enumerate(range(n_components)):\n",
    "    idx = np.where(labels_ds == i)[0]\n",
    "    idx_pos = np.where((labels_ds == i) & (pos.values))[0]\n",
    "    \n",
    "    c=[(0.8-0.8*(i/n_components), 0.4 + 0.2*(i%2), 0.2+0.75*(i/n_components)), ]\n",
    "    ax.scatter(X_2D[idx, 0], X_2D[idx, 1], c=c, \n",
    "               marker='o', s=10, label=f'class {i}')\n",
    "    if len(idx_pos):\n",
    "        ax.scatter(X_2D[idx_pos, 0], X_2D[idx_pos, 1], c=c, \n",
    "           marker='x', s=200, label=f'Positive, class {i}')     \n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GMM results (n=9)\n",
    "\n",
    "**original** outliers: \n",
    "\n",
    "Generally, most outliers are a minority fraction of the same cluster. This looks like a less coherent cluster (points unrelated in t-SNE). \n",
    "\n",
    "GMM agrees with t-SNE on most clusters. \n",
    "AUC-ROC-score 0.96, AUC-PR0.028, P@100 2%\n",
    "\n",
    "**synthetic** outliers: \n",
    "\n",
    "Outliers present in many different clusters. \n",
    "ROC-score: 0.85, P@100 9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. 1 \n",
    "GMM performs clearly better. The reason is that the model fits the data (which consists of ~10 separate clusters) better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_list = list(range(3, 15))\n",
    "gmm_scores_list = [GaussianMixture(n_components=i, covariance_type='full', random_state=1).fit(x_pen).score_samples(x_pen)\n",
    " for i in n_components_list]# try also spherical\n",
    "gmm_roc_scores = [roc_auc_score(y_pen, - y_pred_) for y_pred_ in gmm_scores_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_components_list, gmm_roc_scores, 'b-x', label='ROC AUC [-]')\n",
    "ax.set_xlabel('N clusters')\n",
    "ax.set_ylabel('ROC scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbours\n",
    "\n",
    "Use the scikit-learn NearestNeighbors implementation to get neighbor statistics and outlier scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A 2.\n",
    "The probability of the nearest neighbour of a point being an outlier, conditional on the class membership of that point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# First: verify that the nearest neighbours of outliers are usually outliers (as one may expect from the TSNE plot)\n",
    "clf_nn = NearestNeighbors(n_neighbors=21) # NB: the first neighbour is the point itself\n",
    "clf_nn.fit(x_pen)\n",
    "Nth_neighbour = 1\n",
    "nearest_ns = clf_nn.kneighbors(x_pen)[1][:, Nth_neighbour]\n",
    "\n",
    "print('Fraction of {}st neighbor that is an outlier, conditional on y==1: {:.2%}'.format(Nth_neighbour, \n",
    "y_pen[nearest_ns[y_pen==1]].mean()))\n",
    "      \n",
    "print('Fraction of {}st neighbor that is an outlier, conditional on y==0: {:.2%}'.format(Nth_neighbour, \n",
    "y_pen[nearest_ns[y_pen==0]].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first neighbour of an outlier is an outlier in 90% of the cases. Even the 10th neigbour is an outlier in more than 50 %. Indeed, as observed in t-SNE, outliers are close together in this case. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra: sci-kit learn implementation of KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_distance(X, n_points=1, skip_first_distance=True):\n",
    "    \"\"\"\n",
    "    X (np.array): distance array, shape Nxn_neighbors\n",
    "    n_points (int): number of points to calculate the median distance from\n",
    "    skip_first_distance (boolean or int): if True (or 1), the first column is ignored\n",
    "    \"\"\"\n",
    "    dist_array=np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        dist_array[i] = np.median(X[i][int(skip_first_distance):int(skip_first_distance) + n_points])\n",
    "    return dist_array\n",
    "        \n",
    "def get_outlier_score(x_data, n_neighbors):\n",
    "    \"\"\" Returns a 1-D numpy array with outlier scores\n",
    "    \"\"\"\n",
    "    clf_nb = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "    clf_nb.fit(x_pen)\n",
    "    neighbor_distances = clf_nb.kneighbors()[0] #1st array contains distances, 2nd contains points\n",
    "    median_knn_pen = get_median_distance(neighbor_distances, n_points=n_neighbors)\n",
    "    return median_knn_pen\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try n_neigbours 31 (NB: there are 20 outliers, that are close-by, so choose n larger)\n",
    "n_neighbours = 31\n",
    "knn_scores_sklearn = get_outlier_score(x_pen, n_neighbours)\n",
    "res = plot_outlier_scores(y_pen.values, knn_scores_sklearn, bw=0.1, \n",
    "                          title='Pen digits, KNN. (n={})'.format(n_neighbours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Use pyod to get outlier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.knn import KNN\n",
    "\n",
    "# train kNN detector\n",
    "n_neighbours = 31\n",
    "\n",
    "clf = KNN(method='median', n_neighbors=n_neighbours)\n",
    "clf.fit(x_pen)\n",
    "# get the prediction label and outlier scores of the training data\n",
    "y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "knn_scores = clf.decision_scores_  # raw outlier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_outlier_scores(y_pen.values, knn_scores, bw=0.1, \n",
    "                          title='Pen digits, KNN. (n={})'.format(clf.n_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_top_N(y_pen.values, knn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN results\n",
    "\n",
    "**Original** outliers:\n",
    "\n",
    "With k=31, ROC-score is 0.98, and P@100 is 8.0% (8 positives) \n",
    "\n",
    "**Synthetic** outliers:\n",
    "\n",
    "With k=31, ROC-score is 0.88, and P@100 is 12.0% (12 positives) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. 3\n",
    "Comparing scores for a range of n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over a range of n_neighbours\n",
    "n_neighbour_list = [1+i*5 for i in range(20)]\n",
    "knn_scores_list = [KNN(method='median', n_neighbors=n).fit(x_pen).decision_scores_\n",
    "                  for n in n_neighbour_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "knn_roc_auc_scores = [roc_auc_score(y_pen, knn_score) for knn_score in knn_scores_list]\n",
    "knn_ap_auc_scores = [average_precision_score(y_pen, knn_score) for knn_score in knn_scores_list]\n",
    "N_ = 100\n",
    "knn_precision_at_N = [y_pen[np.argsort(knn_score)][::-1][:N_].mean() for knn_score in knn_scores_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax.plot(n_neighbour_list, knn_roc_auc_scores, 'b-x', label='ROC AUC [-]')\n",
    "ax2.plot(n_neighbour_list, knn_ap_auc_scores, 'g-x', label='AP AUC [-]')\n",
    "ax2.plot(n_neighbour_list, knn_precision_at_N, 'r-x', label=f'Precision@{N_}')\n",
    "ax.set_xlabel('N neighbours');\n",
    "ax.set_ylim([0.0, 1])\n",
    "ax.set_ylabel('AUC score', color='b');\n",
    "ax2.set_ylabel(f'Precision@{N_}', color='r');\n",
    "ax2.set_ylim([0, 0.2])\n",
    "ax.legend()\n",
    "ax2.legend()\n",
    "ax.set_title('KNN results');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. 3.\n",
    "**Original** outliers:\n",
    "\n",
    "Optimal k is about 30 (both AUC-ROC and AUC-PR and p@100). \n",
    "\n",
    "Precision@100 is much stronger affected by n_neighbours than the AUC-ROC score. The precision@100 and AUC-AP correspond well in their trends.  \n",
    "\n",
    "Choosing n_neighbours too high leads to a dilution of the scores and a strong decrease in the top-100 precision.\n",
    "\n",
    "**Synthetic** outliers:\n",
    "\n",
    "Optimal k is rather small, 5 or 10, for both ROC and P@100. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A 4.\n",
    "\n",
    "LOF compares the \"reachability-density\" of an object to the average density of its neighbours. The reachability-density is an inverse of the reachability distance, which puts a lower limit on the distance between two points that is given on the distance of the kth-nearest neighbour. Points that are part of one cluster all have a similar density, and thus get a score of around 1. An isolated point has a much lower density than its nearest neighbour when that neighbour is part of a dense cluster, and gets a high outlier score. \n",
    "\n",
    "Since in the pendigits data outliers are clustered together, they may easily have comparable densities. Thus, when the value for K is too small (smaller than the cluster size), the algorithm will not detect differences in densities, and fail to recognize the outliers. \n",
    "\n",
    "LOF with k=10 can thus be expected to perform worse than KNN. \n",
    "\n",
    "https://en.wikipedia.org/wiki/Local_outlier_factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1:** N_neighbours = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.lof import LOF\n",
    "\n",
    "n_neighbours = 10\n",
    "lof = LOF(n_neighbors=n_neighbours, contamination=0.01)\n",
    "lof.fit(x_pen)\n",
    "lof_scores = lof.decision_scores_\n",
    "res = plot_outlier_scores(y_pen.values, lof_scores, \n",
    "                          bw=0.02, title=f'Pen digits, LOF. (n={n_neighbours})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2:** N_neighbours = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbours = 50\n",
    "lof = LOF(n_neighbors=n_neighbours, contamination=0.01)\n",
    "lof.fit(x_pen)\n",
    "lof_scores = lof.decision_scores_\n",
    "\n",
    "res = plot_outlier_scores(y_pen.values, lof_scores, \n",
    "                          bw=0.02, title=f'Pen digits, LOF. (n={n_neighbours})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A 5.\n",
    "n_neighbours of about 50 seems suitable. Clearly, it needs to be larger than the number of outliers (in the original data), since these form a single cluster. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra: compare scores for a range of n_neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over a range of n_neighbours\n",
    "n_neighbour_list = [1+i*5 for i in range(20)]\n",
    "lof_scores_list = [LOF(n_neighbors=n).fit(x_pen).decision_scores_\n",
    "                  for n in n_neighbour_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_roc_auc_scores = [roc_auc_score(y_pen, score) for score in lof_scores_list]\n",
    "lof_ap_auc_scores = [average_precision_score(y_pen, score) for score in lof_scores_list]\n",
    "\n",
    "N_ = 100\n",
    "lof_precision_at_N = [y_pen[np.argsort(score)][::-1][:N_].mean() for score in lof_scores_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax.plot(n_neighbour_list, lof_roc_auc_scores, 'b-x', label='ROC AUC [-]')\n",
    "ax2.plot(n_neighbour_list, lof_ap_auc_scores, 'g-x', label=f'AP AUC [-]')\n",
    "ax2.plot(n_neighbour_list, lof_precision_at_N, 'r-x', label=f'Precision@{N_}')\n",
    "ax.set_xlabel('N neighbours');\n",
    "ax.set_ylim([0.75, 1])\n",
    "ax.set_ylabel('AUC score', color='b');\n",
    "ax2.set_ylabel(f'Precision@{N_}', color='r');\n",
    "ax2.set_ylim([0, 0.2])\n",
    "\n",
    "ax.set_title('LOF results');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOF results\n",
    "\n",
    "**Original** outliers:\n",
    "Note that LOF requires indeed a large n_neighbours to spot the outliers (for the AUC metric), whereas this dilutes the results, giving a worse precision@100. \n",
    "\n",
    "LOF is clearly less suited to this particular dataset. \n",
    "\n",
    "\n",
    "With k=10, LOF has a ROC score of 0.59, which is hardly better than random guessing. \n",
    "\n",
    "With k=50 ROC is 0.93. P@100 is optimal at low k (max 2%), whereas ROC requires k=50\n",
    " or larger.\n",
    " \n",
    " \n",
    "**Synthetic** outliers:\n",
    "Good results for k between 5 and 50.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A 6.\n",
    "\n",
    "Isolation Forest makes splits in an orthogonal fashion. This means it is not rotationally invariant, and it will generate artefacts (points being easier to split in one of the axis directions).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running with n_estimators=1000 and 1024 samples is generally okay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "ifo = IForest(n_estimators=1000, max_samples=1024, random_state=1, contamination=0.01, behaviour='new')\n",
    "ifo.fit(x_pen)\n",
    "# NB: in contradiction to the documentation, there is no .decision_scores_ attribute for iForest\n",
    "iforest_scores = ifo.decision_scores_ #ifo.decision_function(x_pen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_outlier_scores(y_pen.values, iforest_scores, bw=0.01, title='Pen digits (Isolation Forest)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_top_N(y_pen.values, iforest_scores, N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results isolation Forest\n",
    "\n",
    "**Original** outliers:\n",
    "\n",
    "AUC-ROC score 0.88, AUC-PR score 0.009, P@rank100 is 0\n",
    " \n",
    " \n",
    "**Synthetic** outliers:\n",
    "\n",
    "ROC score 0.73, P@rank100 is 1%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A 4.3 (Optional)\n",
    "Running several isoForest's and comparing scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the rather large variation of AUC ROC scores for `n_estimators`=100, by doing 10 calculations with different random seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "n_estimators=100\n",
    "ifo_clfs = [IsolationForest(n_estimators=n_estimators, max_samples=512, \n",
    "                            random_state=i, contamination=0.01)\n",
    "            .fit(x_pen) for i in range(10)]\n",
    "ifo_roc_scores = [roc_auc_score(y_pen.values, -ifo_clf.decision_function(x_pen)) for ifo_clf in ifo_clfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_xlabel('AUC (ROC)')\n",
    "sns.swarmplot(ifo_roc_scores, ax=ax);\n",
    "ax.set_title(f'Scatter in AUC, n estimators {n_estimators}');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**original** outliers: \n",
    "\n",
    "With 100 trees: between 0.80 and 0.88\n",
    "\n",
    "With 1000 trees: between 0.83 and 0.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PCA reconstruction error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. 7\n",
    "\n",
    "This is actually not an easy question at all. One may look at the explained variance ratio, but there is no golden rule for a cut-off here either. This is a parameter that can not be intuitively chosen (unlike the k in kNN). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from pyod.models.pca import PCA as pyod_PCA\n",
    "\n",
    "# NBA: the pyod PCA is implemented differently, and does not seem to work as intended \n",
    "# pca = pyod_PCA(n_components=5, weighted=False, n_selected_components=5, standardization=True).fit(x_pen)\n",
    "# pca.fit(x_pen)\n",
    "# pca_scores = pca.decision_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=16, whiten=False)\n",
    "pca_tf = pca.fit_transform(x_pen)\n",
    "plt.bar(x=range(1, 17), height=1 - pca.explained_variance_ratio_.cumsum());\n",
    "plt.ylabel('Average relative reconstruction error');\n",
    "plt.xlabel('Number of components');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=8, whiten=False)\n",
    "pca_tf = pca.fit_transform(x_pen)\n",
    "x_pen_recon = pca.inverse_transform(pca_tf)\n",
    "pca_scores = ((x_pen - x_pen_recon)**2).mean(axis=1).values\n",
    "#pca_scores = np.clip(pca_scores, 0, 200) # clip for plotting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_outlier_scores(y_pen.values, pca_scores, bw=0.02, title='Pen digits, Mahalonobis (Through PCA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_top_N(y_pen.values, pca_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_list = []\n",
    "recon_error_list = []\n",
    "auc_list = []\n",
    "for i, n_components in enumerate(range(1, 15)):\n",
    "    pca = PCA(n_components=n_components, whiten=False)\n",
    "    pca_tf = pca.fit_transform(x_pen)\n",
    "    x_pen_recon = pca.inverse_transform(pca_tf)\n",
    "    pca_scores_ = ((x_pen - x_pen_recon)**2).mean(axis=1).values\n",
    "    recon_error_list.append(1 - pca.explained_variance_ratio_[-1])\n",
    "    n_components_list.append(n_components)\n",
    "    auc_list.append(roc_auc_score(y_pen, pca_scores_))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recon_error_list, auc_list)\n",
    "for x, y, text in zip(recon_error_list, auc_list, n_components_list):\n",
    "    plt.text(x, y, text)\n",
    "plt.xlabel('Explained variance ratio')\n",
    "plt.ylabel('AUC score');\n",
    "plt.title('Explained variance ratio and AUC as f(n_components)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. 8\n",
    "PCA scores: \n",
    "**Original** outliers:\n",
    "\n",
    "Best results PCA (n_components 8): AUC-ROC score 0.89, AUC-PR 0.015. P@rank100 is 0\n",
    " \n",
    " \n",
    "**Synthetic** outliers:\n",
    "\n",
    "Best results PCA (n_components 9): ROC score 0.89\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. 9\n",
    "\n",
    "Since the data is not bounded between (-1, 1), and may become negative as well as positive, we can't use a sigmoid or (r)elu activation function. A linear activation function is the correct choice. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "\n",
    "clf = AutoEncoder(\n",
    "    hidden_neurons=[10, 8, 10],\n",
    "    hidden_activation='elu',\n",
    "    output_activation='linear',\n",
    "    optimizer='adam',\n",
    "    epochs=15,\n",
    "    batch_size=16,\n",
    "    dropout_rate=0.0,\n",
    "    l2_regularizer=0.0,\n",
    "    validation_size=0.1,\n",
    "    preprocessing=False, #NB: this uses sklearn's StandardScaler\n",
    "    verbose=1,\n",
    "    random_state=1,\n",
    "    contamination=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_pen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc_scores = clf.decision_scores_  # raw outlier scores\n",
    "res = plot_outlier_scores(y_pen.values, autoenc_scores, bw=0.1, title='Pen digits, Autoencoder outlier scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_top_N(y_pen.values, autoenc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra: check the reconstruction error visually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_idx = list(y_pen[y_pen==1].index)[:3]\n",
    "negative_idx = list(y_pen[y_pen==0].index)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the original with the reconstruction to get a feeling (in StandardScaled space)\n",
    "def show_reconstruction(clf, data, index, ax, title=''):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.values\n",
    "    data_recon = clf.model_.predict(data[[index], :])\n",
    "    ax.plot(data[index, :], label='original')\n",
    "    ax.plot(data_recon[0, :], label='reconstructed', linestyle='--');\n",
    "    ax.legend()\n",
    "    ax.set_title(title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(16, 7))\n",
    "titles = ['Outlier', 'Inlier']\n",
    "for i, idxs in enumerate([positive_idx, negative_idx]):\n",
    "    for j, idx in enumerate(idxs):\n",
    "        score = '{:.3f}'.format(autoenc_scores[idx])\n",
    "        show_reconstruction(clf, x_pen, index=idx, ax=axs[i, j], title=titles[i]  + f' (index {idx}, score {score})'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoencoder results \n",
    "\n",
    "**Original** outliers:\n",
    "Autoencoder, With (10, 8, 10) ROC score 0.87, P@rank100 is 1%\n",
    " \n",
    " \n",
    "(**Synthetic** outliers):\n",
    "Autoencoder, With (10, 8, 10) ROC score 0.86, P@rank100 is 5%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a matrix with all the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {'mahalanobis':mahalonobis_scores,\n",
    "                'knn':knn_scores,\n",
    "               'lof':lof_scores,\n",
    "               'gmm':gmm_scores,\n",
    "               'iforest':iforest_scores,\n",
    "               'pca':pca_scores,\n",
    "               'autoenc':autoenc_scores}\n",
    "\n",
    "results_dict= {'auc-roc':{alg:roc_auc_score(y_pen, score) for alg, score in scores_dict.items()},\n",
    "              'auc-pr':{alg:average_precision_score(y_pen, score) for alg, score in scores_dict.items()}}\n",
    "results_df = pd.DataFrame(results_dict).sort_values(by='auc-roc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[:, 'auc-roc'].plot(kind='bar')\n",
    "plt.title('AUC-ROC scores');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[:, 'auc-pr'].plot(kind='bar');\n",
    "plt.title('AUC-PR scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. 10\n",
    "\n",
    "For the **original** outlier data, the best algorithms are KNN and the GMM. \n",
    "Both these algorithms require a single parameter, which may be possible to estimate (number of neighbours, number of clusters). In both cases, the algorithms are pretty robust with respect to the exact parameter value. \n",
    "\n",
    "\n",
    "For the **synthetic** outlier data, LOF and PCA are the winner, closely followed by KNN, the Autoencoder and the GMM model. Isolation Forest does not do too well here. For both PCA and the Autoencoder, it is difficult to guess good parameter settings. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_pen, knn_scores)\n",
    "plt.plot(recall[:-1], precision[:-1]);\n",
    "plt.xlabel('Recall');\n",
    "plt.ylabel('Precision');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra:  DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dbscan_outlierscore(labels):\n",
    "    \"\"\" Returns outlier scores from db scan labels\n",
    "    The -1 cluster are defined as outliers, and get the highest outlier score\n",
    "    Other clusters: the smaller the cluster, the larger the outlier score\n",
    "    \n",
    "    labels (np.ndarray) : cluster labels\n",
    "    \n",
    "    Returns: outlier_scores (np.ndarray)\n",
    "    \"\"\"\n",
    "    cluster_counter = Counter(labels)\n",
    "    del cluster_counter[-1] # Outliers will get score 1 at the end\n",
    "    cluster_label, cluster_size = (np.array(list(cluster_counter.keys())), \n",
    "                                   np.array(list(cluster_counter.values())))\n",
    "    \n",
    "    cluster_order = cluster_label[np.argsort(cluster_size)][::-1]\n",
    "    scores = np.array(range(len(cluster_label))) / len(cluster_label)\n",
    "    cluster_mapping = {c:s for c, s in zip(cluster_order, scores)}\n",
    "    cluster_mapping = {**cluster_mapping, -1:1}\n",
    "    outlier_scores = np.vectorize(cluster_mapping.get)(labels)\n",
    "    return outlier_scores\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN has two parameters to choose. min_samples has a smaller influence than epsilon. Larger epsilon results in fewer clusters. A somewhat smaller epsilon (resulting in ~10 clusters) seems beneficial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "\n",
    "db = DBSCAN(eps=1.5, min_samples=10)\n",
    "db.fit(x_pen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_outlier_scores = make_dbscan_outlierscore(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(db.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_outlier_scores(y_pen.values, db_outlier_scores, bw=0.025, title='Pen digits, Mahalonobis (Through PCA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_top_N(y_pen.values, db_outlier_scores, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_scores_dbscan = {eps: roc_auc_score(y_pen.values, \n",
    "                                        make_dbscan_outlierscore(DBSCAN(eps=eps, min_samples=10)\n",
    "                                                                 .fit(x_pen)\n",
    "                                                                 .labels_)) \n",
    "                     for eps in  [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(roc_scores_dbscan.keys()), list(roc_scores_dbscan.values()), '-x');\n",
    "plt.xlabel('Epsilon value')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('DBSCAN: epsilon versus Area under ROC curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.ocsvm import OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocsvm_clf = OCSVM(gamma='auto', kernel='rbf')\n",
    "ocsvm_clf.fit(x_pen)\n",
    "ocsvm_scores = ocsvm_clf.decision_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plot_outlier_scores(y_pen, ocsvm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame()\n",
    "scores_df['knn_scores'] = knn_scores\n",
    "scores_df['gmm_scores'] = gmm_scores\n",
    "scores_df['lof_scores'] = lof_scores\n",
    "scores_df['iforest_scores'] = iforest_scores\n",
    "scores_df['autoenc_scores'] = autoenc_scores\n",
    "scores_df['dbscan_scores'] = db_outlier_scores\n",
    "scores_df['ocsvm_scores'] = ocsvm_scores\n",
    "scores_df['mahalonobis_scores'] = mahalonobis_scores\n",
    "\n",
    "sns.pairplot(scores_df);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}