{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DonErnesto/amld2021-unsupervised/blob/master/notebooks/challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ek6rUiPXRC-"
   },
   "source": [
    "# Workshop challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FsyJ1d24Z9Je"
   },
   "source": [
    "## Package installing and data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the required files...\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab, need to get data and install libraries..')\n",
    "    data_path = './'\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/amld2021-unsupervised/master/notebooks/outlierutils.py\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/amld2021-unsupervised/master/data/x_kdd.csv\n",
    "    !curl -O https://raw.githubusercontent.com/DonErnesto/amld2021-unsupervised/master/data/x_kdd_prepared.csv\n",
    "    !pip install --upgrade pyod\n",
    "else:\n",
    "    print('Not running on CoLab, data and libraries are already present')\n",
    "    data_path = '../data'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import getpass\n",
    "\n",
    "# pandas, seaborn etc.\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn outlier models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# other sklearn functions\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.covariance import MinCovDet, EmpiricalCovariance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import scale as preproc_scale\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# pyod\n",
    "import pyod\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "# from pyod.models.pca import PCA as pyod_PCA\n",
    "from pyod.models.iforest import IForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlierutils import plot_top_N, plot_outlier_scores, LabelSubmitter, API_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'x_kdd_prepared.csv'\n",
    "x = pd.read_csv(os.path.join(data_path, dataset_path))\n",
    "print(f'Data set size: {x.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Description\n",
    "\n",
    "You have just imported a data set, `x_kdd`, with 48K rows. The dataset was collected by by MIT Lincoln Labs in 1999, by operating a LAN-network as usual and additionally carrying out various attacks. This specific dataset (which is a subset of the original dataset) has \"normal\" traffic as inlier class, and several attacks (buffer_overflow, ftp_write, imap, ...) as outlier class. Although this data does not represent payment fraud, it is relevant because of the mixed data type.\n",
    "\n",
    "The goal of the challenge is for you to tell which rows are the outliers, i.e. which rows correspond to network attacks.\n",
    "\n",
    "There are no labels available. The target is to predict as many true positives as possible and as few false positives as possible, with the following weights:\n",
    "\n",
    "- Each true positive reported yields **500** points\n",
    "- Each false positive reported costs **25** points\n",
    "\n",
    "You submit your prediction (the indices of the rows that you think are outliers) to a server by means of of some code discussed below. The server will provide feedback: it will tell you which rows are actually outliers and which ones are not.\n",
    "\n",
    "**Hints**\n",
    "- proceed iteratively! Submit a few points, learn based on the feedback of the server, then submit a few more points, etc..\n",
    "- only submit points that you think are positives!! Just submitting all points, or random points, will not get you a good score :)\n",
    "- the fraction of positives is less than 1%. Random guessing to gather labels is therefore unlikely to pay off. \n",
    "- given the limited time available for the workshop, we have already cleaned the data for you. If you rather do the cleaning yourself, set `dataset_path = 'x_kdd.csv'` in the cell above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Outlier detection code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here!!\n",
    "# by using one or more than one method, you will estimate a vector of scores, like this\n",
    "\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "\n",
    "ifo = IForest(n_estimators=1000, max_samples=1024, random_state=1, contamination=0.01, behaviour='new')\n",
    "ifo.fit(x)\n",
    "# get the outlier scores of the data\n",
    "scores_ifo = ifo.decision_scores_  # raw outlier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(scores_ifo)[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a submission process\n",
    "\n",
    "Given the `scores` array, you may want to submit for example the indices of the N points that have the highest score. You can use this helper function to calculate these indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_N_indices(scores, N=100):\n",
    "    \"\"\" Helper function. Returns the indices of the points with the top N highest outlier scores\n",
    "    \"\"\"\n",
    "    return np.argsort(scores)[::-1][:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_submission = get_top_N_indices(scores_ifo, N=40)\n",
    "indices_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example `score` vector `scores_example = np.array([5.23, 4.12, 1.45, 7.23, 19.2, 2.23])`, the N=2 highest scoring points are at indices 4 and 3 in the original table, captured in the `indices_submission` vector above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API submission\n",
    "\n",
    "Submit your predictions to the API with the `LabelSubmitter` class. \n",
    "This class has two useful methods:\n",
    "- with `.post_predictions()` you submit the indices of the estimated outliers. Submitting more than once the same index has no additional effect on your score \n",
    "- with `.get_labels()` you retrieve the label (1 for outliers and 0 for inliers) of all previously submitted indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username='your_user_name'\n",
    "password = getpass.getpass()\n",
    "if not ('server' in locals() and server.jwt_token): #only if no labelsubmitter with .jwt_token is available\n",
    "    server = LabelSubmitter(username=username,\n",
    "                       password=password,\n",
    "                       url=API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the parameter `endpoint='kdd'` option for this challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "server.post_predictions(idx=indices_submission, endpoint='kdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = server.get_labels(endpoint='kdd')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
